import os
import yfinance as yf
import google.generativeai as genai
import psycopg2
import json
import urllib.parse as urlparse
from datetime import datetime
import re # å¼•å…¥æ­£åˆ™ç”¨äºç²¾ç¡®æå– JSON

genai.configure(api_key=os.getenv("GEMINI_API_KEY"))
model = genai.GenerativeModel('gemini-2.5-flash')

def extract_json(text):
    """å®‰å…¨åœ°ä» AI æ–‡æœ¬ä¸­æå– JSON æ•°ç»„æˆ–å¯¹è±¡"""
    try:
        # ä½¿ç”¨æ­£åˆ™åŒ¹é…æœ€å¤–å±‚çš„ [ ] æˆ– { }
        match = re.search(r'(\[.*\]|\{.*\})', text, re.DOTALL)
        if match:
            return json.loads(match.group(1))
        return None
    except:
        return None

def run_production_scanner():
    watch_list = ["RKLB", "ASTS", "AMZN", "NBIS", "GOOGL", "RDDT", "MU", "SOFI", "POET", "AMD", 
                  "IREN", "HOOD", "RIVN", "NVDA", "ONDS", "LUNR", "APLD", "TSLA", "PLTR", "META", 
                  "NVO", "AVGO", "PATH", "PL", "NFLX", "OPEN", "ANIC", "TMC", "FNMA", "UBER"]
    
    scan_time = datetime.now()
    market_data_block = []
    iv_pool = []

    print(f"ğŸ“¡ æ‰«æå¯åŠ¨: {scan_time}")

    for ticker in watch_list:
        try:
            s = yf.Ticker(ticker)
            price = s.fast_info['last_price']
            opt_dates = s.options
            avg_iv = 0
            if opt_dates:
                chain = s.option_chain(opt_dates[0])
                avg_iv = float(chain.calls['impliedVolatility'].mean())
                iv_pool.append({"ticker": ticker, "iv": avg_iv})
            
            market_data_block.append(f"[{ticker}] Price: ${price:.2f}, IV: {avg_iv:.2%}")
        except: continue

    # --- 1. é«˜ IV ä¸“é¡¹åˆ†æ ---
    top_5_iv = sorted(iv_pool, key=lambda x: x['iv'], reverse=True)[:5]
    if top_5_iv:
        iv_context = ", ".join([f"{x['ticker']}({x['iv']:.1%})" for x in top_5_iv])
        iv_prompt = f"åˆ†æè¿™5ä¸ªé«˜IVè‚¡ç¥¨çš„åŸå› ï¼š{iv_context}ã€‚è¿”å›JSONæ ¼å¼: [{{'ticker':'...', 'reason':'...'}}]"
        
        iv_response = model.generate_content(iv_prompt)
        # ä½¿ç”¨å¢å¼ºè§£æ
        iv_analysis_data = extract_json(iv_response.text)
        
        if not iv_analysis_data:
            print("âš ï¸ AI æœªè¿”å›æœ‰æ•ˆ IV åˆ†æ JSONï¼Œä½¿ç”¨ç©ºåˆ—è¡¨è·³è¿‡ã€‚")
            iv_analysis_data = []
    else:
        iv_analysis_data = []

    # --- 2. 6æ­¥åè®®ç­–ç•¥å»ºè®® ---
    # æ­¤å¤„çœç•¥ä½ ä¹‹å‰çš„ trade_prompt é€»è¾‘ï¼ŒåŒæ ·ä½¿ç”¨ extract_json å¤„ç†è¿”å›
    final_trades = [] # å‡è®¾ä½ å·²ç»è·å–å¹¶ç”¨ extract_json å¤„ç†äº†ç»“æœ

    # --- 3. æ•°æ®åº“å…¥åº“ ---
    try:
        url = urlparse.urlparse(os.getenv("DATABASE_URL"))
        conn = psycopg2.connect(database=url.path[1:], user=url.username, password=url.password, host=url.hostname, port=url.port, sslmode='require')
        cur = conn.cursor()

        # å†™å…¥é«˜ IV æ•°æ®
        for item in iv_analysis_data:
            iv_val = next((x['iv'] for x in top_5_iv if x['ticker'] == item['ticker']), 0)
            cur.execute("INSERT INTO public.iv_analysis (ticker, iv_value, analysis_reason, scan_timestamp) VALUES (%s, %s, %s, %s)",
                        (item['ticker'], iv_val, item['reason'], scan_time))
        
        conn.commit()
        cur.close()
        conn.close()
        print(f"âœ… æˆåŠŸå…¥åº“ {len(iv_analysis_data)} æ¡ IV åˆ†æã€‚")
    except Exception as e:
        print(f"âŒ æ•°æ®åº“å†™å…¥å¤±è´¥: {e}")

if __name__ == "__main__":
    run_production_scanner()