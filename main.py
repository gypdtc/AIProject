import os
import base64
import io
import json
import psycopg2
from datetime import datetime
from fastapi import FastAPI, Request
from fastapi.middleware.cors import CORSMiddleware
import google.generativeai as genai
from PIL import Image

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

DATABASE_URL = os.getenv("DATABASE_URL")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
INTERNAL_AUTH_KEY = os.getenv("INTERNAL_AUTH_KEY")
genai.configure(api_key=GEMINI_API_KEY)
GEMINI_MODEL_NAME = "gemini-2.5-flash"

def save_to_db(ticker, sentiment, author, post_time, reason):
    """å¢å¼ºç‰ˆå…¥åº“å‡½æ•°ï¼šæ”¯æŒå‘å¸–äººå’Œå‘å¸–æ—¶é—´"""
    conn = None
    try:
        conn = psycopg2.connect(DATABASE_URL)
        cur = conn.cursor()
        
        # å³ä½¿ Ticker ç›¸åŒï¼Œåªè¦ Author æˆ– Post_Time ä¸åŒï¼Œå°±æ˜¯æ–°çš„æœ‰æ•ˆè®°å½•
        sql = """
        INSERT INTO stock_trends (ticker, sentiment, author, post_time, reason, source) 
        VALUES (%s, %s, %s, %s, %s, %s)
        """
        params = (
            ticker.upper(), 
            sentiment.capitalize(), 
            author, 
            post_time, 
            reason, 
            "ChromeExtension"
        )
        
        cur.execute(sql, params)
        conn.commit()
        cur.close()
        print(f"âœ… å·²è®°å½•: {author} å‘å¸ƒçš„ {ticker} ({sentiment})")
    except Exception as e:
        print(f"âŒ æ•°æ®åº“å†™å…¥å¤±è´¥: {e}")
    finally:
        if conn:
            conn.close()

@app.post("/analyze")
async def analyze_route(request: Request):
    auth_key = request.headers.get("X-Internal-Key")
    if not INTERNAL_AUTH_KEY or auth_key != INTERNAL_AUTH_KEY:
        return {"status": "error", "message": "Unauthorized"}

    try:
        data = await request.json()
        image_bytes = base64.b64decode(data['image'].split(',')[1])
        img = Image.open(io.BytesIO(image_bytes))

        # è·å–å½“å‰æ—¶é—´ä¼ ç»™ AIï¼Œæ–¹ä¾¿å®ƒè®¡ç®—â€œ3å°æ—¶å‰â€çš„å…·ä½“æ—¥æœŸ
        now_str = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

        print(f"--- å¼€å§‹ AI åˆ†æ (å½“å‰å‚è€ƒæ—¶é—´: {now_str}) ---")
        
        model = genai.GenerativeModel(GEMINI_MODEL_NAME)
        prompt = f"""
        ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¤¾äº¤åª’ä½“æ•°æ®æŠ“å–åŠ©æ‰‹ã€‚
        å½“å‰ç³»ç»Ÿå‚è€ƒæ—¶é—´æ˜¯: {now_str}ã€‚
        
        ä»»åŠ¡ï¼šåˆ†æè¿™å¼  Reddit æˆ–å°çº¢ä¹¦çš„æˆªå›¾ï¼Œæå–ä»¥ä¸‹ä¿¡æ¯ï¼š
        1. æåŠçš„è‚¡ç¥¨ä»£ç  (ticker)
        2. æƒ…ç»ª (sentiment: Bullish/Bearish/Neutral)
        3. å‘å¸–äººç”¨æˆ·å (author: å¦‚æœæ‰¾ä¸åˆ°åˆ™å¡« Unknown)
        4. åŸå§‹å‘å¸–æ—¶é—´ (post_time: å¦‚æœæ˜¯'2h ago'è¯·è®¡ç®—å‡ºå…·ä½“æ—¶é—´ï¼Œæ ¼å¼ YYYY-MM-DD HH:MM:SS)
        
        è¯·ä¸¥æ ¼è¿”å› JSON æ•°ç»„ï¼Œä¾‹å¦‚:
        [
          {{"ticker": "NVDA", "sentiment": "Bullish", "author": "UserA", "post_time": "2026-01-01 18:00:00"}},
          {{"ticker": "AAPL", "sentiment": "Bearish", "author": "UserB", "post_time": "2026-01-01 17:30:00"}}
        ]
        ä¸è¦è¿”å›ä»»ä½• Markdown æ ‡è®°ã€‚
        """
        
        response = model.generate_content([prompt, img])
        raw_text = response.text.strip().replace("```json", "").replace("```", "")
        analysis_results = json.loads(raw_text)

        # éå†ç»“æœå¹¶å…¥åº“
        for item in analysis_results:
            save_to_db(
                ticker=item.get('ticker'),
                sentiment=item.get('sentiment'),
                author=item.get('author', 'Unknown'),
                post_time=item.get('post_time', now_str), # é»˜è®¤ä½¿ç”¨å½“å‰æ—¶é—´
                reason="AI Vision Extraction"
            )
        
        return {"status": "success", "count": len(analysis_results), "data": analysis_results}

    except Exception as e:
        print(f"ğŸš¨ è¿è¡Œå¼‚å¸¸: {e}")
        return {"status": "error", "message": str(e)}

if __name__ == "__main__":
    import uvicorn
    port = int(os.environ.get("PORT", 8080))
    uvicorn.run(app, host="0.0.0.0", port=port)